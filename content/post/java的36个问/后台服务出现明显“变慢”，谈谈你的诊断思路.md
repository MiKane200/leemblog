## 变慢
1. 首先，需要对这个问题进行更加清晰的定义:
    1. 服务是突然变慢还是长时间运行后观察到变慢？类似问题是否重复出现？
    2. “慢”的定义是什么，我能够理解是系统对其他方面的请求的反应延时变长吗?
2. 第二，理清问题的症状，这更便于定位具体的原因，有以下一些思路：
    1. 问题可能来自于Java服务自身，也可能仅仅是受系统里其他服务的影响。初始判断可以先确认是否出现了意外的程序错误，例如检查应用本身的错误日志。
    2. 对于分布式系统，很多公司都会实现更加系统的日志、性能等监控系统。一些Java诊断工具也可以用于这个诊断，例如通过JFR（Java Flight Recorder），监控应用是否大量出现了某种类型的异常。如果有，那么异常可能就是个突破点。
    3. 如果没有，可以先检查系统级别的资源等情况，监控CPU、内存等资源是否被其他进程大量占用，并且这种占用是否不符合系统正常运行状况。
    4. 监控Java服务自身，例如GC日志里面是否观察到Full GC等恶劣情况出现，或者是否Minor GC在变长等；利用jstat等工具，获取内存使用的统计信息也是个常用手段；利用jstack等工具检查是否出现死锁等。
    5. 如果还不能确定具体问题，对应用进行Profiling也是个办法，但因为它会对系统产生侵入性，如果不是非常必要，大多数情况下并不建议在生产系统进行。
    6. 定位了程序错误或者JVM配置的问题后，就可以采取相应的补救措施，然后验证是否解决，否则还需要重复上面部分过程。

## 怎么找到最耗费CPU的Java线程，简要介绍步骤：
1. 利用top命令获取相应pid，“-H”代表thread模式，你可以配合grep命令更精准定位。`top –H`
2. 然后转换成为16进制。`printf "%x" your_pid`
3. 最后利用jstack获取的线程栈，对比相应的ID即可。

## 除了CPU，内存和IO是重要的注意事项，比如：
1. 利用free之类查看内存使用。
2. 或者，进一步判断swap使用情况，top命令输出中Virt作为虚拟内存使用量，就是物理内存（Res）和swap求和，所以可以反推swap使用。显然，JVM是不希望发生大量的swap使用的。
3. 对于IO问题，既可能发生在磁盘IO，也可能是网络IO。例如，利用iostat等命令有助于判断磁盘的健康状况。我曾经帮助诊断过Java服务部署在国内的某云厂商机器上，其原因就是IO表现较差，拖累了整体性能，解决办法就是申请替换了机器。

## 对于JVM层面的性能分析，我们已经介绍过非常多了：
1. 利用JMC、JConsole等工具进行运行时监控。
2. 利用各种工具，在运行时进行堆转储分析，或者获取各种角度的统计数据（如jstat -gcutil分析GC、内存分带等）。
3. GC日志等手段，诊断Full GC、Minor GC，或者引用堆积等。

## 对于应用Profiling
简单来说就是利用一些侵入性的手段，收集程序运行时的细节，以定位性能问题瓶颈。所谓的细节，就是例如内存的使用情况、最频繁调用的方法是什么，或者上下文切换的情况等。

一般不建议生产系统进行Profiling，大多数是在性能测试阶段进行。但是，当生产系统确实存在这种需求时，也不是没有选择。建议使用JFR配合JMC来做Profiling，因为它是从Hotspot JVM内部收集底层信息，并经过了大量优化，性能开销非常低，通常是低于 2% 的；并且如此强大的工具，也已经被Oracle开源出来！

JFR/JMC完全具备了生产系统Profiling的能力，目前也确实在真正大规模部署的云产品上使用过相关技术，快速地定位了问题。

它的使用也非常方便，你不需要重新启动系统或者提前增加配置。例如，你可以在运行时启动JFR记录，并将这段时间的信息写入文件：
`Jcmd <pid> JFR.start duration=120s filename=myrecording.jfr`
然后，使用JMC打开“.jfr文件”就可以进行分析了，方法、异常、线程、IO等应有尽有，其功能非常强大。